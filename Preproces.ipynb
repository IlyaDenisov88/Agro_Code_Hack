{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eznnJAAuKsTA",
        "outputId": "754a3cf8-13e1-48f4-9c4f-0de34473fb69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pymystem3 in /usr/local/lib/python3.10/dist-packages (0.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from pymystem3) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->pymystem3) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->pymystem3) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->pymystem3) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->pymystem3) (2023.7.22)\n"
          ]
        }
      ],
      "source": [
        "!pip install pymorphy2 > None\n",
        "!pip install pymystem3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "from string import punctuation\n",
        "import pymorphy2\n",
        "from nltk.stem.snowball import RussianStemmer\n",
        "nltk.download('stopwords')\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "nltk.download('punkt')\n",
        "from pymystem3 import Mystem\n",
        "from sklearn.mixture import GaussianMixture"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AnbVrM8YLVUq",
        "outputId": "2283f6b8-b4df-41e6-f7e5-7c2729e3b695"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def hh_job_preparation_was(string):\n",
        "    global global_counter_modify_jobs\n",
        "\n",
        "    result = string.lower()\n",
        "\n",
        "    temp_string = result\n",
        "\n",
        "    result = result.replace(\"зам. \", \"заместитель \")\n",
        "    result = result.replace(\"нач. \", \"начальник \")\n",
        "    result = result.replace(\"рук. \", \"руководитель \")\n",
        "    result = result.replace(\"ген. \", \"генеральный \")\n",
        "    result = result.replace(\"гендиректор\", \"генеральный директор\")\n",
        "    result=result.replace(\"вет.\", \"ветеринарный\")\n",
        "    result = result.replace(\"ветврач\", \"ветеринарный врач\")\n",
        "    result = result.replace(\"гл.\", \"главный\")\n",
        "    result = result.replace(\"гл\", \"главный\")\n",
        "    result = result.replace(\"–\", \"-\")\n",
        "    result = result.replace(\" - \", \"-\")\n",
        "\n",
        "    if (result.find(\"(\")>0 and result.find(\")\")>0):\n",
        "        temp = \"\"\n",
        "        not_closed = False\n",
        "        for i in range(len(result)):\n",
        "            if result[i] == \"(\":\n",
        "                not_closed = True\n",
        "            elif result[i] == \")\":\n",
        "                not_closed = False\n",
        "            else:\n",
        "                if not not_closed:\n",
        "                    temp += result[i]\n",
        "        result = temp\n",
        "\n",
        "    if (result.find(\"«\")>0 and result.find(\"»\")>0):\n",
        "        temp = \"\"\n",
        "        not_closed = False\n",
        "        for i in range(len(result)):\n",
        "            if result[i] == \"«\":\n",
        "                not_closed = True\n",
        "            elif result[i] == \"»\":\n",
        "                not_closed = False\n",
        "            else:\n",
        "                if not not_closed:\n",
        "                    temp += result[i]\n",
        "        result = temp\n",
        "\n",
        "\n",
        "    if (result.find(\",\") > 0) :\n",
        "        result=result.partition(',')[0]\n",
        "\n",
        "    if (result.find(\";\") > 0) :\n",
        "        result=result.partition(';')[0]\n",
        "\n",
        "    if (result.find(\".\") > 0) :\n",
        "        result=result.partition('.')[0]\n",
        "\n",
        "    if (result.find(\"/\") > 0) :\n",
        "        result=result.partition('/')[0]\n",
        "\n",
        "    if (result.find(\" по \") > 0) :\n",
        "        result=result.partition(' по ')[0]\n",
        "\n",
        "\n",
        "    if (result.find(\"начальник \") > -1 or result.find(\"руководитель \") > -1):\n",
        "        if (result.find(\"отдела\") > -1):\n",
        "            result = \"начальник отдела\"\n",
        "        elif (result.find(\"службы\") > -1):\n",
        "            result = \"начальник службы\"\n",
        "        elif (result.find(\"управления\") > -1):\n",
        "            result = \"начальник управления\"\n",
        "        elif (result.find(\"подразделения\") > -1):\n",
        "            result = \"начальник подразделения\"\n",
        "        elif (result.find(\"группы\") > -1):\n",
        "            result = \"начальник группы\"\n",
        "    if (result.find(\"агроном\") > -1):\n",
        "      result = \"начальник отдела\"\n",
        "    if (result.find(\"ветеринарный врач\") > -1):\n",
        "      result = \"ветеринарный врач\"\n",
        "    if (result.find(\"бригадир\") > -1):\n",
        "      result = \"бригадир\"\n",
        "    for i in range(10):\n",
        "        if str(i) in result:\n",
        "          result=result[:result.find(str(i))]\n",
        "\n",
        "    if (result.find(\"заместитель начальника\") > -1 or result.find(\"заместитель руководителя \") > -1):\n",
        "        if (result.find(\"отдела\") > -1):\n",
        "            result = \"заместитель начальника отдела\"\n",
        "        elif (result.find(\"службы\") > -1):\n",
        "            result = \"заместитель начальника службы\"\n",
        "        elif (result.find(\"управления\") > -1):\n",
        "            result = \"заместитель начальника управления\"\n",
        "        elif (result.find(\"подразделения\") > -1):\n",
        "            result = \"заместитель начальника подразделения\"\n",
        "        elif (result.find(\"группы\") > -1):\n",
        "            result = \"заместитель начальника группы\"\n",
        "\n",
        "    if (result.find(\"developer\") > -1 or result.find(\"programmer\") > -1 ):\n",
        "        result=\"программист\"\n",
        "\n",
        "    if (result.find(\"генеральный директор\") > -1 or result.find(\"programmer\") > -1 ):\n",
        "        result=\"генеральный директор\"\n",
        "\n",
        "    result=result.strip()\n",
        "\n",
        "    if (result != temp_string):\n",
        "        global_counter_modify_jobs = global_counter_modify_jobs +1\n",
        "\n",
        "\n",
        "    return(result)"
      ],
      "metadata": {
        "id": "14mtzRrDLdP_"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "punct= list(punctuation)\n",
        "punct.append(' ')\n",
        "stopwords = nltk.corpus.stopwords.words('russian')\n",
        "stopwords.append('\\n')\n",
        "def hh_description_prepar(string):\n",
        "    result = string.lower()\n",
        "    txt= word_tokenize(result)          #токенизация\n",
        "    txt = [i for i in txt if i not in punct and i not in stopwords]\n",
        "    #lemm=Mystem()\n",
        "    #txt = lemm.lemmatize(\" \".join(txt))      #лемматизация\n",
        "    morph = pymorphy2.MorphAnalyzer()\n",
        "    lemms_text = [morph.parse(i)[0].normal_form for i in txt]\n",
        "    stemmer = RussianStemmer()\n",
        "    stems_lemms_low_txt_punct_stopword = [stemmer.stem(i) for i in lemms_text]    #стемминг\n",
        "    return \" \".join(txt)"
      ],
      "metadata": {
        "id": "l73jcs0cLi_B"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_2=pd.read_json('data_frame2.json')"
      ],
      "metadata": {
        "id": "0tWVG0dnMe2q"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "global_counter_modify_jobs=0\n",
        "corpus_prof_1=data_2['Prof_1']\n",
        "corpus_prof_2=data_2['Prof_2']\n",
        "\n",
        "corpus_new_prof_1=[ hh_job_preparation_was(i) for  i in corpus_prof_1]\n",
        "corpus_new_prof_2=[ hh_job_preparation_was(i) for  i in corpus_prof_2]\n",
        "corpus_desc=data_2['Description_1']\n",
        "corpus_new_desc=[ hh_description_prepar(i) for  i in corpus_desc ]\n"
      ],
      "metadata": {
        "id": "alE7BW18Mh5E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = TfidfVectorizer()\n",
        "TF_IDF_vector_prof_1= vectorizer.fit_transform(corpus_prof_1).toarray()\n",
        "\n",
        "TF_IDF_vector_new_prof_1=[]\n",
        "for i in TF_IDF_vector_prof_1:            #создаю копию списка в более удобном формате\n",
        "  part=[]\n",
        "  for j in i:\n",
        "    part.append(j)\n",
        "  TF_IDF_vector_new_prof_1.append(part)\n",
        "TF_IDF_vector_prof_2= vectorizer.fit_transform(corpus_prof_2).toarray()\n",
        "TF_IDF_vector_new_prof_2=[]\n",
        "for i in TF_IDF_vector_prof_2:            #создаю копию списка в более удобном формате\n",
        "  part=[]\n",
        "  for j in i:\n",
        "    part.append(j)\n",
        "  TF_IDF_vector_new_prof_2.append(part)"
      ],
      "metadata": {
        "id": "Cj5tZZE4MnGo"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = TfidfVectorizer()\n",
        "\n",
        "TF_IDF_vector_desc= vectorizer.fit_transform(corpus_new_desc).toarray()\n",
        "TF_IDF_vector_new_desc=[]\n",
        "for i in TF_IDF_vector_desc:            #создаю копию списка в более удобном формате\n",
        "  part=[]\n",
        "  for j in i:\n",
        "    part.append(j)\n",
        "  TF_IDF_vector_new_desc.append(part)\n"
      ],
      "metadata": {
        "id": "Lm-KR8hgMpf6"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_2['Prepare prof_1']=corpus_prof_1\n",
        "data_2['Prepare prof_2']=corpus_prof_2\n",
        "data_2['Prepare prof_1 tfidf']=TF_IDF_vector_new_prof_1\n",
        "data_2['Prepare prof_2 tfidf']=TF_IDF_vector_new_prof_2\n",
        "data_2['Prepare description']=corpus_new_desc\n",
        "data_2['Prepare description tfidf']=TF_IDF_vector_new_desc\n",
        "\n",
        "data_2.to_json('/content/data_with_prepare_job.json')"
      ],
      "metadata": {
        "id": "sB1DVXyyMsj1"
      },
      "execution_count": 9,
      "outputs": []
    }
  ]
}